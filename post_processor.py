import pandas as pd
import os
import re
import traceback

def intelligent_split(text: str, delimiter: str):
    """
    Splits a string by a delimiter and then processes each part to separate 
    a name from a model in parentheses.
    
    Returns a tuple of two lists: (names, models)
    """
    names, models = [], []
    # Don't split if delimiter is not in the string
    if delimiter not in text:
        text_list = [text]
    else:
        text_list = [s.strip() for s in text.split(delimiter)]
        
    for part in text_list:
        match = re.search(r'(.+?)\s*[ï¼ˆ(](.+?)[)ï¼‰]$', part)
        if match:
            names.append(match.group(1).strip())
            models.append(match.group(2).strip())
        else:
            # If no parenthesis, the whole part is the name/spec, and model is N/A
            names.append(part)
            models.append('N/A')
    return names, models

def process_file(input_path, logger=None):
    """
    Processes a raw CSV file using a prioritized delimiter approach.
    It iterates through a list of delimiters. For each row, it uses the first
    delimiter that successfully splits the 'core columns' into an equal number of items.
    """
    def log_message(msg):
        if logger and hasattr(logger, 'put'):
            logger.put(msg)
        else:
            print(msg)

    if not os.path.exists(input_path):
        log_message(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return None

    try:
        directory, filename = os.path.split(input_path)
        name, ext = os.path.splitext(filename)
        output_path = os.path.join(directory, f"{name}_processed.csv")
        
        log_message(f"â–¶ï¸ å¼€å§‹ä½¿ç”¨[åˆ†éš”ç¬¦ä¼˜å…ˆçº§]åŸåˆ™å¤„ç†æ–‡ä»¶: {filename}")

        df = pd.read_csv(input_path).fillna('')
        new_rows = []
        # åˆ†éš”ç¬¦æŒ‰ä¼˜å…ˆçº§æ’åºï¼šåˆ†å· > é¡¿å· > æ¢è¡Œç¬¦ > ç«–çº¿
        prioritized_delimiters = [';', 'ï¼›', 'ã€', '\n', '|']

        for index, row in df.iterrows():
            row_dict = row.to_dict()
            
            # --- Get string representations of all relevant columns ---
            name_str = str(row_dict.get('åç§°', '')).strip()
            brand_str = str(row_dict.get('å“ç‰Œ', '')).strip()
            spec_str = str(row_dict.get('è§„æ ¼å‹å·', '')).strip()
            count_str = str(row_dict.get('æ•°é‡', '')).strip()
            price_str = str(row_dict.get('å•ä»·', '')).strip()

            if any('è¯¦è§é™„ä»¶' in s for s in [name_str, spec_str, count_str, price_str]):
                log_message(f"    - â„¹ï¸  ç¬¬ {index + 2} è¡ŒåŒ…å« 'è¯¦è§é™„ä»¶'ï¼Œè·³è¿‡æ‹†åˆ†ã€‚")
                row_dict['split_status'] = 'attachment'
                new_rows.append(row_dict)
                continue

            split_successful = False
            for delim in prioritized_delimiters:
                # --- Attempt to split core columns with the current delimiter ---
                new_names, new_specs = intelligent_split(spec_str, delim)
                counts = [s.strip() for s in count_str.split(delim) if s.strip()]
                prices = [s.strip() for s in price_str.split(delim) if s.strip()]

                core_lengths = [len(new_specs), len(counts), len(prices)]
                
                # --- Check for core alignment ---
                is_core_aligned = all(x == core_lengths[0] for x in core_lengths)
                num_items = core_lengths[0] if is_core_aligned else 0

                if is_core_aligned and num_items > 1:
                    # --- If core is aligned, check non-core columns ---
                    brands = [s.strip() for s in brand_str.split(delim) if s.strip()]
                    non_core_lengths = [len(new_names), len(brands)]
                    
                    are_non_core_valid = all(l == 1 or l == num_items for l in non_core_lengths)

                    if are_non_core_valid:
                        # --- SUCCESS: Split the row and break from the delimiter loop ---
                        log_message(f"    - âœ… ç¬¬ {index + 2} è¡Œä½¿ç”¨åˆ†éš”ç¬¦ '{delim}' æˆåŠŸåŒ¹é…ï¼Œæ‹†åˆ†ä¸º {num_items} æ¡ã€‚")
                        for i in range(num_items):
                            new_item = row_dict.copy()
                            new_item['åç§°'] = new_names[i]
                            new_item['å“ç‰Œ'] = brands[i if len(brands) == num_items else 0]
                            new_item['è§„æ ¼å‹å·'] = new_specs[i]
                            new_item['æ•°é‡'] = counts[i]
                            new_item['å•ä»·'] = prices[i]
                            new_item['split_status'] = 'ok'
                            new_rows.append(new_item)
                        
                        split_successful = True
                        break # Exit the delimiter loop for this row

            if not split_successful:
                # --- Did not split: Append original row ---
                all_lengths = [len(re.split(r'[ã€ï¼›;\n|]', s)) for s in [name_str, brand_str, spec_str, count_str, price_str]]
                is_single = all(l <= 1 for l in all_lengths)
                
                if not is_single:
                    log_message(f"    - âš ï¸ ç¬¬ {index + 2} è¡Œæœªä½¿ç”¨ä»»ä½•ä¼˜å…ˆåˆ†éš”ç¬¦æˆåŠŸåŒ¹é…ï¼Œè·³è¿‡æ‹†åˆ†ã€‚")
                    row_dict['split_status'] = 'mismatched'
                else:
                    row_dict['split_status'] = 'single_item'
                new_rows.append(row_dict)

        if not new_rows:
            log_message("ğŸ¤·â€â™‚ï¸ æ–‡ä»¶å¤„ç†åæ²¡æœ‰æ•°æ®ã€‚")
            return None

        processed_df = pd.DataFrame(new_rows)
        processed_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        log_message(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œæ–‡ä»¶å·²ä¿å­˜åˆ°: {os.path.basename(output_path)}")
        return output_path
    
    except Exception as e:
        log_message(f"âŒ åœ¨ process_file ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        log_message(traceback.format_exc())
        return None

if __name__ == '__main__':
    class ConsoleLogger:
        def put(self, message):
            print(message)
    
    logger = ConsoleLogger()
    test_file_path = r'output\ä¸­æ ‡å…¬å‘Š_ç©ºè°ƒ_æ±Ÿè‹_2025-06-11_to_2025-06-12.csv'
    
    if os.path.exists(test_file_path):
        process_file(test_file_path, logger)
    else:
        logger.put(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file_path}") 