import pandas as pd
import os
import traceback

def process_file(input_path, logger=None):
    """
    Processes a single CSV file to expand rows with multiple items.

    Args:
        input_path (str): The path to the input CSV file.
        logger (object, optional): A logger object with a `put` method. Defaults to None.

    Returns:
        str: Path to the processed file, or None if processing failed.
    """
    def log_message(msg):
        if logger and hasattr(logger, 'put'):
            logger.put(msg)
        else:
            print(msg)

    try:
        if not os.path.exists(input_path):
            log_message(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {input_path}")
            return None

        log_message(f"â–¶ï¸ å¼€å§‹å¤„ç†æ–‡ä»¶: {os.path.basename(input_path)}")
        df = pd.read_csv(input_path)
        
        processed_rows = []
        
        # Define the columns to be split
        # We use a dictionary to map the main column to its potential split-mates
        # This makes the logic more robust if some columns don't need splitting
        columns_to_split = ["åç§°", "è§„æ ¼å‹å·", "æ•°é‡", "å•ä»·"]
        
        for index, row in df.iterrows():
            # Use the 'åç§°' column as the trigger for splitting
            trigger_column = "åç§°"
            
            if isinstance(row[trigger_column], str) and 'ã€' in row[trigger_column]:
                # Split all relevant columns by the delimiter 'ã€'
                split_data = {col: str(row[col]).split('ã€') for col in columns_to_split if col in row and isinstance(row[col], str)}

                # Find the number of items to split into
                num_items = len(split_data.get(trigger_column, []))

                # If for some reason the split results in an empty list, skip
                if num_items == 0:
                    processed_rows.append(row.to_dict())
                    continue
                
                # Verify that all splittable columns have the same number of items
                is_consistent = all(len(items) == num_items for items in split_data.values())
                
                if not is_consistent:
                    log_message(f"    - âš ï¸ è­¦å‘Š: ç¬¬ {index + 2} è¡Œæ•°æ®ä¸ä¸€è‡´ï¼Œè·³è¿‡æ‹†åˆ†ã€‚å„åˆ—æ‹†åˆ†åçš„é¡¹ç›®æ•°ä¸åŒã€‚")
                    processed_rows.append(row.to_dict())
                    continue

                log_message(f"    - â„¹ï¸ æ­£åœ¨å°†ç¬¬ {index + 2} è¡Œæ‹†åˆ†ä¸º {num_items} æ¡è®°å½•...")
                for i in range(num_items):
                    new_row = row.to_dict()
                    for col, items in split_data.items():
                        new_row[col] = items[i].strip()
                    processed_rows.append(new_row)
            else:
                # If no delimiter is found, add the row as is
                processed_rows.append(row.to_dict())

        if not processed_rows:
            log_message("    - ğŸ¤·â€â™‚ï¸ å¤„ç†åæœªç”Ÿæˆä»»ä½•æ•°æ®ã€‚")
            return None

        # Create a new DataFrame from the processed rows
        processed_df = pd.DataFrame(processed_rows)
        
        # Define output path
        directory, filename = os.path.split(input_path)
        name, ext = os.path.splitext(filename)
        output_filename = f"{name}_processed{ext}"
        output_path = os.path.join(directory, output_filename)
        
        # Save the processed DataFrame
        processed_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        log_message(f"âœ… å¤„ç†å®Œæˆï¼Œæ–‡ä»¶å·²ä¿å­˜åˆ°: {output_filename}")
        
        return output_path

    except Exception as e:
        log_message(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        log_message(traceback.format_exc())
        return None

if __name__ == '__main__':
    # Example usage:
    # Create a dummy logger for standalone testing
    class ConsoleLogger:
        def put(self, message):
            print(message)
            
    logger = ConsoleLogger()
    
    # Specify the file to process directly
    # You can change this path to test with other files
    test_file_path = r'output\\å››å·_ç©ºè°ƒ_2025-05-18_to_2025-05-19.csv'
    
    if os.path.exists(test_file_path):
        process_file(test_file_path, logger=logger)
    else:
        logger.put(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file_path}") 